
<!DOCTYPE html>
<html lang="en">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="/theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="/theme/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="/theme/font-awesome/css/font-awesome.min.css">





  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />


<meta name="author" content="Peter Frick" />
<meta name="description" content="In the last post we built the data preprocessing required for word2vec training. In this post we will build the network and perform the training on the text8 dataset (source), a Wikipedia dump of ~17 million tokens. Note that we are implementing the skip-gram version of word2vec since it has superior performance" />
<meta name="keywords" content="python, machine learning, tensorflow, nlp, prediction, word2vec">
<meta property="og:site_name" content="Peter Frick"/>
<meta property="og:title" content="word2vec part 2: graph building and training"/>
<meta property="og:description" content="In the last post we built the data preprocessing required for word2vec training. In this post we will build the network and perform the training on the text8 dataset (source), a Wikipedia dump of ~17 million tokens. Note that we are implementing the skip-gram version of word2vec since it has superior performance"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/training-word2vec-on-text8.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2018-04-03 00:00:00+02:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="/author/peter-frick.html">
<meta property="article:section" content="blog"/>
<meta property="article:tag" content="python"/>
<meta property="article:tag" content="machine learning"/>
<meta property="article:tag" content="tensorflow"/>
<meta property="article:tag" content="nlp"/>
<meta property="article:tag" content="prediction"/>
<meta property="article:tag" content="word2vec"/>
<meta property="og:image" content="https://raw.githubusercontent.com/frickp/insight/master/FrickHeadshot.jpg">

  <title>Peter Frick &ndash; word2vec part 2: graph building and training</title>

</head>
<body>
  <aside>
    <div>
      <a href="">
        <img src="https://raw.githubusercontent.com/frickp/insight/master/FrickHeadshot.jpg" alt="" title="">
      </a>
      <h1><a href=""></a></h1>


      <nav>
        <ul class="list">
          <li><a href="/pages/about-me.html#about-me">About me</a></li>

          <li><a href="http://frickp.github.io" target="_blank">Blog</a></li>
          <li><a href="http://greenleaf.stanford.edu" target="_blank">Stanford Genetics</a></li>
          <li><a href="http://insightdatascience.com" target="_blank">Insight Data Science</a></li>
          <li><a href="https://medschool.vanderbilt.edu/cpb/" target="_blank">Vanderbilt systems biology</a></li>
          <li><a href="https://www.linkedin.com/in/peterlfrick/" target="_blank">LinkedIn</a></li>
        </ul>
      </nav>

      <ul class="social">
        <li><a class="sc-LinkedIn" href="https://www.linkedin.com/in/peterlfrick/" target="_blank"><i class="fa fa-LinkedIn"></i></a></li>
        <li><a class="sc-GitHub" href="https://github.com/frickp" target="_blank"><i class="fa fa-GitHub"></i></a></li>
      </ul>
    </div>


  </aside>
  <main>


<article class="single">
  <header>
    <h1 id="training-word2vec-on-text8">word2vec part 2: graph building and training</h1>
    <p>
          Posted on Tue 03 April 2018 in <a href="/category/blog.html">blog</a>


    </p>
  </header>


  <div>
    <style type="text/css">/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}


.rendered_html pre,



.rendered_html tr,
.rendered_html th,

.rendered_html td,


.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,

div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
</style>
<style type="text/css">.highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */</style>
<style type="text/css">
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }
</style><html><body><div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the last post we built the data preprocessing required for word2vec training. In this post we will build the network and perform the training on the text8 dataset (<a href="http://mattmahoney.net/dc/textdata.html">source</a>), a Wikipedia dump of ~17 million tokens.</p>
<p>Note that we are implementing the skip-gram version of word2vec since it has <a href="http://ruder.io/secret-word2vec/index.html#hyperparameters">superior performance</a>. The skip gram model tries to learn: given a center word, try to predict the surrounding words.</p>
<p>Goals:</p>
<ul>
<li>understand skipgram (word2vec) network structure</li>
<li>train model</li>
<li>save/load model variables</li>
<li>find most similar words</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sys</span> <span class="k">import</span> <span class="n">path</span>
<span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'./w2v_tools'</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">w2v_tools</span> <span class="k">import</span> <span class="n">batch_gen_w2v</span><span class="p">,</span> <span class="n">build_dataset</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">'/Users/pf494t/.matplotlib/stylelib/plf.mplstyle'</span><span class="p">)</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/pf494t/anaconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="get-the-source-data-here">get the source data <a href="http://mattmahoney.net/dc/textdata.html">here</a><a class="anchor-link" href="#get-the-source-data-here">¶</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'text8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">text8</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)</span>
    
<span class="n">text8</span> <span class="o">=</span> <span class="n">text8</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">text8</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt output_prompt">Out[3]:</div>
<div class="output_text output_subarea output_execute_result">
<pre>17005207</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Use a <a href="https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/examples/tutorials/word2vec/word2vec_basic.py">pre-written function</a> to build necessary objects for frequency, reverse indexing, etc. These are useful for connecting word indices with embeddings we will learn. Also, they define which words are frequent enough to add in the vocabulary. This ensures that computations for, e.g., the similarity matrix are tractable for time and memory.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocabulary_size</span> <span class="o">=</span> <span class="mi">50000</span>

<span class="n">data</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">,</span> <span class="n">reverse_dictionary</span> <span class="o">=</span> <span class="n">build_dataset</span><span class="p">(</span>
            <span class="n">text8</span><span class="p">,</span> <span class="n">vocabulary_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">del</span> <span class="n">text8</span>  <span class="c1"># reduce memory.</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>data</code> is a list of in-vocabulary word indices, where the lower the number, the more frequent it is</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt output_prompt">Out[6]:</div>
<div class="output_text output_subarea output_execute_result">
<pre>[5234, 3081, 12, 6, 195, 2, 3134, 46, 59, 156]</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>use the batch generator created in the last post to read in data. Note that I added <code>text=data</code> because <code>tf.data.Dataset.from_generator</code> does not expect arguments</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [7]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">gen</span><span class="p">():</span>
    <span class="k">yield from</span> <span class="n">batch_gen_w2v</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-word2vec-network">Build word2vec network<a class="anchor-link" href="#Build-word2vec-network">¶</a></h2><p>As we've seen before, first, we build a graph, then later will use it for learning</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [8]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># paramters fro training</span>
<span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">embedding_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">num_sampled</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="1:-Read-in-the-data">1: Read in the data<a class="anchor-link" href="#1:-Read-in-the-data">¶</a></h4><p>use <code>tf.data.Dataset</code> together with the generator <code>batch_gen_w2v</code> from the last blog post.</p>
<h4 id="2:-Represent-the-data-using-embeddings">2: Represent the data using embeddings<a class="anchor-link" href="#2:-Represent-the-data-using-embeddings">¶</a></h4><p>First initialize the word embeddings in the <code>embeddings</code> Variable from a uniform distribution. These are learned during training. Then use <code>tf.nn.embedding_lookup</code> to create a lookup that bridges word indices and embeddings.</p>
<h4 id="3:-Define-the-layers.">3: Define the layers.<a class="anchor-link" href="#3:-Define-the-layers.">¶</a></h4><p>Word2vec is a single layer network. Therefore, this implementation basically just pushes the input data through <code>tf.nn.nce_loss</code>. See <a href="https://stackoverflow.com/questions/41475180/understanding-tf-nn-nce-loss-in-tensorflow">this explainer</a> on the tensorflow nce implementation. NCE loss works basically by sampling from a noise distribution (words that are not nearby), and computes the loss through binary classification. E.g., <code>nce_weights</code> and <code>nce_bias</code> are similar to learned parameters in logistic regression. The use stochastic gradient descent for learning</p>
<h4 id="4:-Compute-the-cosine-similarity">4: Compute the cosine similarity<a class="anchor-link" href="#4:-Compute-the-cosine-similarity">¶</a></h4><p>This will be useful in looking for similar words. Also, others have used this for visualizations, <em>a la</em> <a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding">t-SNE</a>.</p>
<h4 id="5:-Save-the-model">5: Save the model<a class="anchor-link" href="#5:-Save-the-model">¶</a></h4><p>So we can read in the embeddings later from the checkpoint</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [9]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>   
    <span class="c1"># 1: read in data </span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_generator</span><span class="p">(</span>
            <span class="n">gen</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="n">batch_size</span><span class="p">]),</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">])))</span>

    <span class="n">iterator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="o">.</span><span class="n">from_structure</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">output_types</span><span class="p">,</span>
                                               <span class="n">dataset</span><span class="o">.</span><span class="n">output_shapes</span><span class="p">)</span>

    <span class="n">train_init_op</span> <span class="o">=</span> <span class="n">iterator</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">'training_iterator'</span><span class="p">)</span>
    <span class="n">context</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">iterator</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>
    
    <span class="c1"># 2: Represent the data using embeddings</span>
    <span class="c1"># embeddings for all words</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">vocabulary_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">],</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span><span class="n">name</span><span class="o">=</span><span class="s1">'word_embeddings'</span><span class="p">)</span>
    <span class="c1"># embeddings for the current batch</span>
    <span class="n">embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">'batch_embeddings'</span><span class="p">)</span>

    <span class="c1"># 3: Define the layers</span>
    <span class="c1"># variables for the NCE loss</span>
    <span class="n">nce_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">vocabulary_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">],</span>
                            <span class="n">stddev</span><span class="o">=</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">embedding_size</span><span class="p">),</span><span class="n">name</span><span class="o">=</span><span class="s1">'trunc_norm'</span><span class="p">),</span><span class="n">name</span><span class="o">=</span><span class="s1">'nce_weights'</span><span class="p">)</span>
    <span class="n">nce_biases</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">vocabulary_size</span><span class="p">]),</span><span class="n">name</span><span class="o">=</span><span class="s1">'nce_bias'</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">nce_loss</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">nce_weights</span><span class="p">,</span>
                     <span class="n">biases</span><span class="o">=</span><span class="n">nce_biases</span><span class="p">,</span>
                     <span class="n">labels</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
                     <span class="n">inputs</span><span class="o">=</span><span class="n">embed</span><span class="p">,</span>
                     <span class="n">num_sampled</span><span class="o">=</span><span class="n">num_sampled</span><span class="p">,</span>
                     <span class="n">num_classes</span><span class="o">=</span><span class="n">vocabulary_size</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">'nce_loss'</span><span class="p">),</span><span class="n">name</span><span class="o">=</span><span class="s1">'nce_loss_reduced'</span><span class="p">)</span>

    <span class="c1"># SGD optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
    <span class="c1"># 4: Compute the cosine similarity</span>
    <span class="c1"># normalize, then dot product, then sort</span>
    <span class="n">normed_embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">l2_normalize</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">'normed_embeddings'</span><span class="p">)</span>
    <span class="n">normed_array</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">l2_normalize</span><span class="p">(</span><span class="n">embed</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">'normed_batch_embeddings'</span><span class="p">)</span>

    <span class="n">cosine_similarity</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">normed_array</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">normed_embedding</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span><span class="n">name</span><span class="o">=</span><span class="s1">'cos_sim'</span><span class="p">)</span>
    <span class="n">closest_words</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">cosine_similarity</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">'k_most_similar'</span><span class="p">)</span>
    
    <span class="c1"># 5: Save the model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train-the-model-and-save-the-outputs">Train the model and save the outputs<a class="anchor-link" href="#Train-the-model-and-save-the-outputs">¶</a></h2><p>use 500,000 epochs. Total $epochs * batchsize$: <code>1e6 * 32 = 3.2e7</code>. So we are basically iterating twice over the whole sequence</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [10]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">1000000</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">g</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span> <span class="c1"># initialize everything</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_init_op</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">l</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">loss</span><span class="p">,</span><span class="n">optimizer</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
    <span class="n">cw</span><span class="p">,</span> <span class="n">ct</span><span class="p">,</span> <span class="n">e1</span><span class="p">,</span> <span class="n">e2</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">closest_words</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">normed_array</span><span class="p">,</span> <span class="n">normed_embedding</span><span class="p">])</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s2">"./models/w2v_pt2.ckpt"</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Plot-the-loss-over-the-course-of-training">Plot the loss over the course of training<a class="anchor-link" href="#Plot-the-loss-over-the-course-of-training">¶</a></h3><p>plot the rolling average (over 20 epochs)</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [11]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">s</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [12]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'NCE loss'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'epochs (thousands)'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Restore-variables">Restore variables<a class="anchor-link" href="#Restore-variables">¶</a></h4><p><a href="http://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/">this</a> is a great resource</p>
<p>We can get the embeddings in a couple of ways. First, they should be stored in <code>cw</code> using the above cell by manually computing cosine similarity then using <code>tf.nn.top_k</code> to get the top words.</p>
<p>Let's just load it from file for practice. It was a bit awkward for me to get this. Notice that <code>'word_embeddings:0'</code> is not what I named the layer initially, nor is it what I saw when I looked at the checkpoint (see below).</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [13]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">new_saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="s1">'models/w2v_pt2.ckpt.meta'</span><span class="p">)</span>
    <span class="n">new_saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s1">'models/'</span><span class="p">))</span>
    <span class="n">saved_embeddings</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="s1">'word_embeddings:0'</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from models/w2v_pt2.ckpt
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Load in the embeddings</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [14]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">saved_embeddings</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt output_prompt">Out[14]:</div>
<div class="output_text output_subarea output_execute_result">
<pre>(50000, 64)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="normalize-the-embeddings">normalize the embeddings<a class="anchor-link" href="#normalize-the-embeddings">¶</a></h4><p>Using standard L2</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [15]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">normalize_embeddings</span><span class="p">(</span><span class="n">emb</span><span class="p">):</span>
    <span class="n">emb_shape</span> <span class="o">=</span> <span class="n">emb</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">sq_emb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">emb</span><span class="p">)</span> 
    <span class="n">sos_emb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sq_emb</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">emb_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">normed_emb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sos_emb</span><span class="p">))</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'test.pickle'</span><span class="p">,</span><span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">normed_emb</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>    
    <span class="k">return</span> <span class="n">normed_emb</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [16]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">normed_embedding</span> <span class="o">=</span> <span class="n">normalize_embeddings</span><span class="p">(</span><span class="n">saved_embeddings</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Get-a-similarity-matrix">Get a similarity matrix<a class="anchor-link" href="#Get-a-similarity-matrix">¶</a></h4><p>of all pairwise comparisons. Note that this could not compute using (100000, 100) dataset. I think this can be done by writing iteratively to file rather than keeping everything in memory. Instead I used smaller data size (50000, 64)</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [17]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">calc_cos_sim</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">cos_sim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span><span class="n">emb</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
    <span class="k">if</span> <span class="n">save</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'cos_sim.pickle'</span><span class="p">,</span><span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">cos_sim</span><span class="p">,</span><span class="n">f</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cos_sim</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [18]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cos_sim</span> <span class="o">=</span> <span class="n">calc_cos_sim</span><span class="p">(</span><span class="n">normed_embedding</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Find-the-words-most-similar-to-a-given-word">Find the words most similar to a given word<a class="anchor-link" href="#Find-the-words-most-similar-to-a-given-word">¶</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [19]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">most_similar</span><span class="p">(</span><span class="n">sim_matrix</span><span class="p">,</span><span class="n">word</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">k_most_similar</span><span class="o">=</span><span class="mi">10</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">word</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">dictionary</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    <span class="n">word_index</span> <span class="o">=</span> <span class="n">dictionary</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
    <span class="n">word_vec</span> <span class="o">=</span> <span class="n">sim_matrix</span><span class="p">[</span><span class="n">word_index</span><span class="p">]</span>
    <span class="c1"># sort, then find the k–most similar, </span>
    <span class="c1"># then display in reverse order ignoring the original word</span>
    <span class="n">similar_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">word_vec</span><span class="p">)[</span><span class="o">-</span><span class="n">k_most_similar</span><span class="p">:][</span><span class="o">-</span><span class="mi">2</span><span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> 
    <span class="k">return</span> <span class="p">[</span><span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">sim_idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">sim_idx</span> <span class="ow">in</span> <span class="n">similar_indices</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [20]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'most similar to army:</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">most_similar</span><span class="p">(</span><span class="n">sim_matrix</span><span class="o">=</span><span class="n">cos_sim</span><span class="p">,</span><span class="n">word</span><span class="o">=</span><span class="s1">'army'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>most similar to army:

</pre>
</div>
</div>
<div class="output_area">
<div class="prompt output_prompt">Out[20]:</div>
<div class="output_text output_subarea output_execute_result">
<pre>['overseas',
 'garment',
 'officer',
 'gradually',
 'gallic',
 'holding',
 'pancreas',
 'gorge',
 'armed',
 'szabo']</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>not bad! We see words like "police" and "navy" and perhaps there were a lot of Cold War articles.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [21]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'most similar to computer:</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">most_similar</span><span class="p">(</span><span class="n">sim_matrix</span><span class="o">=</span><span class="n">cos_sim</span><span class="p">,</span><span class="n">word</span><span class="o">=</span><span class="s1">'computer'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>most similar to computer:

</pre>
</div>
</div>
<div class="output_area">
<div class="prompt output_prompt">Out[21]:</div>
<div class="output_text output_subarea output_execute_result">
<pre>['programming',
 'graphics',
 'technology',
 'network',
 'operating',
 'hardware',
 'tools',
 'oriented',
 'protocol',
 'electronic']</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This one looks very good, pretty much every word is relevant to computers!</p>
<h2 id="I-had-to-try-it...">I had to try it...<a class="anchor-link" href="#I-had-to-try-it...">¶</a></h2><p>The famous example in word2vec is</p>
$$king - man + woman = queen$$<p>How does this model do?</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [22]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">king</span> <span class="o">=</span> <span class="n">normed_embedding</span><span class="p">[</span><span class="n">dictionary</span><span class="p">[</span><span class="s1">'king'</span><span class="p">]]</span>
<span class="n">man</span> <span class="o">=</span> <span class="n">normed_embedding</span><span class="p">[</span><span class="n">dictionary</span><span class="p">[</span><span class="s1">'man'</span><span class="p">]]</span>
<span class="n">woman</span> <span class="o">=</span> <span class="n">normed_embedding</span><span class="p">[</span><span class="n">dictionary</span><span class="p">[</span><span class="s1">'woman'</span><span class="p">]]</span>
<span class="n">kmw</span> <span class="o">=</span> <span class="n">king</span> <span class="o">-</span> <span class="n">man</span> <span class="o">+</span> <span class="n">woman</span>
<span class="n">kmw_sim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">normed_embedding</span><span class="p">,</span><span class="n">kmw</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [23]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'most similar to king - man + woman:</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="p">[</span><span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">word_ix</span><span class="p">]</span> <span class="k">for</span> <span class="n">word_ix</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">kmw_sim</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="mi">10</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>most similar to king - man + woman:

</pre>
</div>
</div>
<div class="output_area">
<div class="prompt output_prompt">Out[23]:</div>
<div class="output_text output_subarea output_execute_result">
<pre>['woman',
 'charles',
 'princess',
 'ii',
 'pka',
 'patron',
 'cosmologies',
 'instructions',
 'gandhi']</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="close,-but-no-cigar!">close, but no cigar!<a class="anchor-link" href="#close,-but-no-cigar!">¶</a></h4><p>Queen is not in the top-most similar list at all, but princess is third most similar. Not bad! Probably would like to add more data and optimize with the gradient descent parameters.</p>
<p>However, it seems to work for actor --&gt; actress (actress is the 4th most similar)!</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [24]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">actor</span> <span class="o">=</span> <span class="n">normed_embedding</span><span class="p">[</span><span class="n">dictionary</span><span class="p">[</span><span class="s1">'actor'</span><span class="p">]]</span>
<span class="n">amw</span> <span class="o">=</span> <span class="n">king</span> <span class="o">-</span> <span class="n">man</span> <span class="o">+</span> <span class="n">woman</span>
<span class="n">amw_sim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">normed_embedding</span><span class="p">,</span><span class="n">kmw</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'most similar to actor - man + woman:</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="p">[</span><span class="n">reverse_dictionary</span><span class="p">[</span><span class="n">word_ix</span><span class="p">]</span> <span class="k">for</span> <span class="n">word_ix</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">amw_sim</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="mi">10</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>most similar to actor - man + woman:

</pre>
</div>
</div>
<div class="output_area">
<div class="prompt output_prompt">Out[24]:</div>
<div class="output_text output_subarea output_execute_result">
<pre>['woman',
 'charles',
 'princess',
 'ii',
 'pka',
 'patron',
 'cosmologies',
 'instructions',
 'gandhi']</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Checkpointing">Checkpointing<a class="anchor-link" href="#Checkpointing">¶</a></h4><p>One last exercise to see what else is saved in the checkpoint</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [25]:</div>
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.python.tools.inspect_checkpoint</span> <span class="k">import</span> <span class="n">print_tensors_in_checkpoint_file</span>
<span class="n">print_tensors_in_checkpoint_file</span><span class="p">(</span>
                                <span class="n">file_name</span><span class="o">=</span><span class="s1">'models/w2v_pt2.ckpt'</span><span class="p">,</span>\
                                <span class="n">tensor_name</span><span class="o">=</span><span class="s1">'k_most_similar'</span><span class="p">,</span>\
                                <span class="n">all_tensors</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>\
                                <span class="n">all_tensor_names</span><span class="o">=</span><span class="kc">True</span>\
                                <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor_name:  nce_bias
[-3.1701143 -2.974355  -3.4008424 ... -1.958728  -2.8562932 -2.3046377]
tensor_name:  nce_weights
[[-0.12722044  0.6649263   0.05840692 ...  0.23179728  0.15671267
   0.06725932]
 [-0.22675377  0.27465826  0.05471431 ...  0.5259495  -0.33893025
   0.00671034]
 [-0.04375689  0.12019156  0.02563075 ...  0.12051834 -0.16042954
   0.078161  ]
 ...
 [-1.0648519   0.90508664  0.34531596 ...  1.115668    0.02313092
  -0.05429195]
 [-0.42834222  1.512869    0.33662498 ...  1.1603873  -0.2990747
  -0.5536745 ]
 [-0.3995957   1.5934845   0.29227847 ...  1.6017785  -0.1760857
  -0.15670015]]
tensor_name:  word_embeddings
[[-0.23668487 -0.4807616  -0.2754368  ... -0.48803067  0.16866484
   0.3305748 ]
 [-0.14941135 -0.24908157  0.08617698 ... -0.3331622  -0.38400456
  -0.11003053]
 [-0.10980351 -0.42675978 -0.1942253  ... -0.67214876 -0.44179285
   0.5734172 ]
 ...
 [ 0.6119225  -0.07231586 -0.3716953  ...  0.19201861  0.6409408
   0.8552471 ]
 [ 0.41137227 -1.1280757   0.35296682 ...  0.41706795 -0.7159017
  -0.6558757 ]
 [-0.297483   -0.58869714 -0.24134146 ... -0.5376434  -0.5510352
  -0.3320802 ]]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Notice that it is only the <code>tf.Variables</code> that are saved. See the above link (in the restore section) for how to use variables read back in</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Conclusions">Conclusions<a class="anchor-link" href="#Conclusions">¶</a></h1><p>Here we implemented a skip–gram model with NCE loss. We trained the model on text 8, and windowed over the sequence of 17 million tokens roughly twice. By computing word similarities, we can wee some interpretability in nearby words, but more data would likely give big improvements in performance.</p>
<p>Also, we could try to use negative sampling to approximate the softmax instead of NCE loss. In the end, this probably would give better performance, because negative sampling implicitly <a href="http://ruder.io/secret-word2vec/">increases the window size</a>, by preferentially skipping frequent words.</p>
<p>This task demonstrated how to:</p>
<ol>
<li>build a graph and feed in a text sequnce for learning</li>
<li>save and extract variables</li>
<li>compute word similarities</li>
</ol>
</div>
</div>
</div>

<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>

  </div>
  <div class="tag-cloud">
    <p>
      <a href="/tag/python.html">python</a>
      <a href="/tag/machine-learning.html">machine learning</a>
      <a href="/tag/tensorflow.html">tensorflow</a>
      <a href="/tag/nlp.html">nlp</a>
      <a href="/tag/prediction.html">prediction</a>
      <a href="/tag/word2vec.html">word2vec</a>
    </p>
  </div>




</article>

    <footer>
<p>&copy; Peter Frick </p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p>    </footer>
  </main>





<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Peter Frick ",
  "url" : "",
  "image": "https://raw.githubusercontent.com/frickp/insight/master/FrickHeadshot.jpg",
  "description": ""
}
</script>
  
</body>
</html>