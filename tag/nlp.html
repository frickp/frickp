
<!DOCTYPE html>
<html lang="en">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="/theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="/theme/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="/theme/font-awesome/css/font-awesome.min.css">





  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />


    <meta name="author" content="Peter Frick" />
    <meta name="description" content="" />
<meta property="og:site_name" content="Peter Frick"/>
<meta property="og:type" content="blog"/>
<meta property="og:title" content="Peter Frick"/>
<meta property="og:description" content=""/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content=""/>
<meta property="og:image" content="https://raw.githubusercontent.com/frickp/insight/master/FrickHeadshot.jpg">

  <title>Peter Frick &ndash;     Tag nlp
</title>

</head>
<body>
  <aside>
    <div>
      <a href="">
        <img src="https://raw.githubusercontent.com/frickp/insight/master/FrickHeadshot.jpg" alt="" title="">
      </a>
      <h1><a href=""></a></h1>


      <nav>
        <ul class="list">
          <li><a href="/pages/about-me.html#about-me">About me</a></li>

          <li><a href="http://frickp.github.io" target="_blank">Blog</a></li>
          <li><a href="http://greenleaf.stanford.edu" target="_blank">Stanford Genetics</a></li>
          <li><a href="http://insightdatascience.com" target="_blank">Insight Data Science</a></li>
          <li><a href="https://medschool.vanderbilt.edu/cpb/" target="_blank">Vanderbilt systems biology</a></li>
          <li><a href="https://www.linkedin.com/in/peterlfrick/" target="_blank">LinkedIn</a></li>
        </ul>
      </nav>

      <ul class="social">
        <li><a class="sc-LinkedIn" href="https://www.linkedin.com/in/peterlfrick/" target="_blank"><i class="fa fa-LinkedIn"></i></a></li>
        <li><a class="sc-GitHub" href="https://github.com/frickp" target="_blank"><i class="fa fa-GitHub"></i></a></li>
      </ul>
    </div>


  </aside>
  <main>




<article>
  <header>
    <h2><a href="/training-word2vec-on-text8.html#training-word2vec-on-text8">word2vec part 2: graph building and training</a></h2>
    <p>
          Posted on Tue 03 April 2018 in <a href="/category/blog.html">blog</a>


          &#8226;     Tagged with

              <a href="/tag/python.html">python</a>,              <a href="/tag/machine-learning.html">machine learning</a>,              <a href="/tag/tensorflow.html">tensorflow</a>,              <a href="/tag/nlp.html">nlp</a>,              <a href="/tag/prediction.html">prediction</a>,              <a href="/tag/word2vec.html">word2vec</a>
    </p>
  </header>
  <div>
      <html><body><div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the last post we built the data preprocessing required for word2vec training. In this post we will build the network and perform the training on the text8 dataset (<a href="http://mattmahoney.net/dc/textdata.html">source</a>), a Wikipedia dump of ~17 million tokens.</p>
<p>Note that we are implementing the skip-gram version of word2vec since it has <a href="http://ruder.io/secret-word2vec/index.html#hyperparameters">superior performance</a>
      <br>
      <a class="btn" href="/training-word2vec-on-text8.html#training-word2vec-on-text8">    Continue reading
</a>
  </div>
  <hr />
</article>
<article>
  <header>
    <h2><a href="/data-flow-for-sequence-models-softmax-expensive.html#data-flow-for-sequence-models-softmax-expensive">word2vec part 1: exploration and defining data flow</a></h2>
    <p>
          Posted on Mon 02 April 2018 in <a href="/category/blog.html">blog</a>


          &#8226;     Tagged with

              <a href="/tag/python.html">python</a>,              <a href="/tag/machine-learning.html">machine learning</a>,              <a href="/tag/tensorflow.html">tensorflow</a>,              <a href="/tag/neural-networds.html">neural networds</a>,              <a href="/tag/nlp.html">nlp</a>
    </p>
  </header>
  <div>
      <html><body><div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>One of the trends I've been seeing is the use of embeddings for similarity/recommendation in non-NLP domains (<a href="https://www.youtube.com/watch?v=JGHVJXP9NHw&amp;list=LLexu7RlzHlP6xuqIgozFcJw&amp;index=4&amp;t=0s">this talk</a> and many others). While I've used/thought about <a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">word2vec</a> for a while, I wanted to implement this to really get a sense of how it works and ways it can be extended to other domains. Intuitively, word2vec makes sense, and there are a lot of packages that will let you compute it without thinking much about the implementation (e.g. <code>gensim</code>
      <br>
      <a class="btn" href="/data-flow-for-sequence-models-softmax-expensive.html#data-flow-for-sequence-models-softmax-expensive">    Continue reading
</a>
  </div>
  <hr />
</article>
<article>
  <header>
    <h2><a href="/neural-networks-text_classification.html#neural-networks-text_classification">Exploring neural networks for text classification</a></h2>
    <p>
          Posted on Fri 17 November 2017 in <a href="/category/blog.html">blog</a>


          &#8226;     Tagged with

              <a href="/tag/python.html">python</a>,              <a href="/tag/machine-learning.html">machine learning</a>,              <a href="/tag/keras.html">keras</a>,              <a href="/tag/nlp.html">nlp</a>,              <a href="/tag/deep-learning.html">deep learning</a>,              <a href="/tag/classification.html">classification</a>
    </p>
  </header>
  <div>
      <html><body><div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I've been working on text classification recently. I've found keras to be a quite good high-level language and great for learning different neural network architectures. In this notebook I will examine Tweet classification using CNN and LSTM model architechtures. While CNNs are widely used in Computer Vision, I saw a <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.717.298&amp;rep=rep1&amp;type=pdf">paper</a>
      <br>
      <a class="btn" href="/neural-networks-text_classification.html#neural-networks-text_classification">    Continue reading
</a>
  </div>
</article>

  <div class="pagination">
  </div>




    <footer>
<p>&copy; Peter Frick </p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p>    </footer>
  </main>





<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Peter Frick ",
  "url" : "",
  "image": "https://raw.githubusercontent.com/frickp/insight/master/FrickHeadshot.jpg",
  "description": ""
}
</script>
  
</body>
</html>